/**
 * ASTRAL_CORE 2.0 AI Decision Audit Trail System
 * 
 * COMPLIANCE & ACCOUNTABILITY FOR AI DECISIONS
 * Maintains comprehensive audit trails for all AI decisions affecting user safety.
 * Ensures regulatory compliance and enables quality improvement through decision analysis.
 */

import { 
  prisma, 
  executeWithMetrics,
  ReportType,
  ReportSeverity 
} from '@astralcore/database';
import { randomUUID } from 'crypto';

export interface AuditEntry {
  id: string;
  timestamp: Date;
  decisionType: 'CONTENT_MODERATION' | 'CRISIS_DETECTION' | 'BEHAVIOR_ANALYSIS' | 'QUALITY_ASSESSMENT' | 'ANOMALY_DETECTION';
  inputData: {
    content?: string;
    context: Record<string, any>;
    userId?: string;
    sessionId?: string;
  };
  aiDecision: {
    riskScore: number;
    confidence: number;
    reasoning: string[];
    categories: string[];
    actions: string[];
  };
  humanOverride?: {
    overriddenBy: string;
    overrideReason: string;
    newDecision: string;
    timestamp: Date;
  };
  outcome?: {
    actualRisk?: number;
    falsePositive?: boolean;
    falseNegative?: boolean;
    userFeedback?: string;
    effectiveness: number;
  };
  compliance: {
    dataRetentionDays: number;
    anonymized: boolean;
    regulatoryFlags: string[];
  };
}

export interface AuditQuery {
  startDate?: Date;
  endDate?: Date;
  decisionType?: string[];
  userId?: string;
  sessionId?: string;
  riskScoreMin?: number;
  riskScoreMax?: number;
  hasHumanOverride?: boolean;
  includeOutcomes?: boolean;
}

export interface AuditAnalysis {
  totalDecisions: number;
  accuracyRate: number;
  falsePositiveRate: number;
  falseNegativeRate: number;
  humanOverrideRate: number;
  averageConfidence: number;
  decisionBreakdown: Record<string, number>;
  riskDistribution: {
    low: number;
    medium: number;
    high: number;
    critical: number;
  };
  timeToDecision: {
    avg: number;
    p95: number;
    p99: number;
  };
}

export class AuditTrailSystem {
  private static instance: AuditTrailSystem;
  
  // Audit configuration
  private readonly AUDIT_CONFIG = {
    MAX_CONTENT_LENGTH: 10000, // Limit stored content for privacy
    RETENTION_DAYS: {
      CRISIS_DETECTION: 2555,      // 7 years (regulatory requirement)
      CONTENT_MODERATION: 1095,    // 3 years
      BEHAVIOR_ANALYSIS: 1825,     // 5 years
      QUALITY_ASSESSMENT: 1095,    // 3 years
      ANOMALY_DETECTION: 730,      // 2 years
    },
    ANONYMIZATION_DELAY: 90, // Days before anonymizing non-critical data
  };
  
  private constructor() {
    console.log('üìã AI Decision Audit Trail System initialized');
    
    // Start cleanup processes
    this.startAuditMaintenance();
  }
  
  static getInstance(): AuditTrailSystem {
    if (!AuditTrailSystem.instance) {
      AuditTrailSystem.instance = new AuditTrailSystem();
    }
    return AuditTrailSystem.instance;
  }
  
  /**
   * Log an AI decision for audit trail
   * TARGET: <50ms logging time to avoid impacting real-time performance
   */
  async logDecision(
    decisionType: AuditEntry['decisionType'],
    inputData: AuditEntry['inputData'],
    aiDecision: AuditEntry['aiDecision']
  ): Promise<string> {
    const startTime = performance.now();
    
    return await executeWithMetrics(async () => {
      const auditId = randomUUID();
      
      // Anonymize sensitive content if needed
      const sanitizedContent = inputData.content 
        ? this.sanitizeContent(inputData.content) 
        : undefined;
      
      // Determine retention period
      const retentionDays = this.AUDIT_CONFIG.RETENTION_DAYS[decisionType];
      
      // Create audit entry
      const auditEntry: AuditEntry = {
        id: auditId,
        timestamp: new Date(),
        decisionType,
        inputData: {
          ...inputData,
          content: sanitizedContent,
        },
        aiDecision,
        compliance: {
          dataRetentionDays: retentionDays,
          anonymized: false,
          regulatoryFlags: this.determineRegulatoryFlags(decisionType, aiDecision),
        },
      };
      
      // Store in database with encryption for sensitive data
      await prisma.auditTrail.create({
        data: {
          id: auditId,
          decisionType,
          timestamp: auditEntry.timestamp,
          inputDataHash: this.hashSensitiveData(inputData),
          inputContext: JSON.stringify(inputData.context),
          userId: inputData.userId,
          sessionId: inputData.sessionId,
          riskScore: aiDecision.riskScore,
          confidence: aiDecision.confidence,
          reasoning: JSON.stringify(aiDecision.reasoning),
          categories: JSON.stringify(aiDecision.categories),
          actions: JSON.stringify(aiDecision.actions),
          retentionDays,
          anonymized: false,
          regulatoryFlags: JSON.stringify(auditEntry.compliance.regulatoryFlags),
        },
      });
      
      const executionTime = performance.now() - startTime;
      
      if (executionTime > 50) {
        console.warn(`‚ö†Ô∏è Audit logging took ${executionTime.toFixed(2)}ms (target: <50ms)`);
      }
      
      // Log critical decisions immediately to monitoring
      if (aiDecision.riskScore >= 0.9 || aiDecision.actions.includes('EMERGENCY_SERVICES_IMMEDIATELY')) {
        console.log(`üìã CRITICAL DECISION LOGGED: ${auditId} - Risk ${(aiDecision.riskScore * 100).toFixed(1)}%`);
        await this.alertComplianceTeam(auditEntry);
      }
      
      return auditId;
      
    }, 'audit-log-decision');
  }
  
  /**
   * Record human override of AI decision
   */
  async recordHumanOverride(
    auditId: string,
    overriddenBy: string,
    overrideReason: string,
    newDecision: string
  ): Promise<void> {
    return await executeWithMetrics(async () => {
      await prisma.auditTrail.update({
        where: { id: auditId },
        data: {
          humanOverrideBy: overriddenBy,
          humanOverrideReason: overrideReason,
          humanOverrideDecision: newDecision,
          humanOverrideTimestamp: new Date(),
        },
      });
      
      console.log(`üë§ Human override recorded: ${auditId} by ${overriddenBy}`);
      
    }, 'audit-record-override');
  }
  
  /**
   * Record decision outcome for learning
   */
  async recordOutcome(
    auditId: string,
    outcome: {
      actualRisk?: number;
      falsePositive?: boolean;
      falseNegative?: boolean;
      userFeedback?: string;
      effectiveness: number;
    }
  ): Promise<void> {
    return await executeWithMetrics(async () => {
      await prisma.auditTrail.update({
        where: { id: auditId },
        data: {
          actualRisk: outcome.actualRisk,
          falsePositive: outcome.falsePositive,
          falseNegative: outcome.falseNegative,
          userFeedback: outcome.userFeedback,
          effectiveness: outcome.effectiveness,
          outcomeRecorded: true,
        },
      });
      
      console.log(`üìä Decision outcome recorded: ${auditId}`);
      
    }, 'audit-record-outcome');
  }
  
  /**
   * Query audit trail with filters
   */
  async queryAuditTrail(query: AuditQuery, limit: number = 1000): Promise<AuditEntry[]> {
    return await executeWithMetrics(async () => {
      const whereClause: any = {};
      
      if (query.startDate) {
        whereClause.timestamp = { gte: query.startDate };
      }
      if (query.endDate) {
        whereClause.timestamp = { ...whereClause.timestamp, lte: query.endDate };
      }
      if (query.decisionType?.length) {
        whereClause.decisionType = { in: query.decisionType };
      }
      if (query.userId) {
        whereClause.userId = query.userId;
      }
      if (query.sessionId) {
        whereClause.sessionId = query.sessionId;
      }
      if (query.riskScoreMin !== undefined) {
        whereClause.riskScore = { gte: query.riskScoreMin };
      }
      if (query.riskScoreMax !== undefined) {
        whereClause.riskScore = { ...whereClause.riskScore, lte: query.riskScoreMax };
      }
      if (query.hasHumanOverride !== undefined) {
        whereClause.humanOverrideBy = query.hasHumanOverride ? { not: null } : null;
      }
      
      const auditRecords = await prisma.auditTrail.findMany({
        where: whereClause,
        orderBy: { timestamp: 'desc' },
        take: limit,
      });
      
      // Convert database records to audit entries
      return auditRecords.map(record => this.dbRecordToAuditEntry(record));
      
    }, 'audit-query-trail');
  }
  
  /**
   * Generate audit analysis report
   */
  async generateAuditAnalysis(
    query: AuditQuery,
    includeTrends: boolean = false
  ): Promise<AuditAnalysis & { trends?: any }> {
    return await executeWithMetrics(async () => {
      const auditEntries = await this.queryAuditTrail(query, 10000);
      
      if (auditEntries.length === 0) {
        return {
          totalDecisions: 0,
          accuracyRate: 0,
          falsePositiveRate: 0,
          falseNegativeRate: 0,
          humanOverrideRate: 0,
          averageConfidence: 0,
          decisionBreakdown: {},
          riskDistribution: { low: 0, medium: 0, high: 0, critical: 0 },
          timeToDecision: { avg: 0, p95: 0, p99: 0 },
        };
      }
      
      // Calculate metrics
      const totalDecisions = auditEntries.length;
      const decisionsWithOutcome = auditEntries.filter(entry => entry.outcome);
      const humanOverrides = auditEntries.filter(entry => entry.humanOverride);
      
      // Accuracy metrics
      const falsePositives = decisionsWithOutcome.filter(entry => entry.outcome?.falsePositive).length;
      const falseNegatives = decisionsWithOutcome.filter(entry => entry.outcome?.falseNegative).length;
      const accurateDecisions = decisionsWithOutcome.length - falsePositives - falseNegatives;
      
      const accuracyRate = decisionsWithOutcome.length > 0 
        ? accurateDecisions / decisionsWithOutcome.length 
        : 0;
      
      const falsePositiveRate = decisionsWithOutcome.length > 0 
        ? falsePositives / decisionsWithOutcome.length 
        : 0;
      
      const falseNegativeRate = decisionsWithOutcome.length > 0 
        ? falseNegatives / decisionsWithOutcome.length 
        : 0;
      
      // Other metrics
      const humanOverrideRate = humanOverrides.length / totalDecisions;
      const averageConfidence = auditEntries.reduce((sum, entry) => 
        sum + entry.aiDecision.confidence, 0) / totalDecisions;
      
      // Decision breakdown
      const decisionBreakdown: Record<string, number> = {};
      auditEntries.forEach(entry => {
        decisionBreakdown[entry.decisionType] = (decisionBreakdown[entry.decisionType] || 0) + 1;
      });
      
      // Risk distribution
      const riskDistribution = {
        low: auditEntries.filter(entry => entry.aiDecision.riskScore < 0.3).length,
        medium: auditEntries.filter(entry => entry.aiDecision.riskScore >= 0.3 && entry.aiDecision.riskScore < 0.7).length,
        high: auditEntries.filter(entry => entry.aiDecision.riskScore >= 0.7 && entry.aiDecision.riskScore < 0.9).length,
        critical: auditEntries.filter(entry => entry.aiDecision.riskScore >= 0.9).length,
      };
      
      // Time metrics (mock implementation - would calculate actual decision times)
      const timeToDecision = {
        avg: 85, // Average 85ms
        p95: 150, // 95th percentile: 150ms
        p99: 200, // 99th percentile: 200ms
      };
      
      const analysis: AuditAnalysis = {
        totalDecisions,
        accuracyRate,
        falsePositiveRate,
        falseNegativeRate,
        humanOverrideRate,
        averageConfidence,
        decisionBreakdown,
        riskDistribution,
        timeToDecision,
      };
      
      // Add trends if requested
      if (includeTrends) {
        const trends = await this.calculateTrends(auditEntries);
        return { ...analysis, trends };
      }
      
      return analysis;
      
    }, 'audit-generate-analysis');
  }
  
  /**
   * Export audit data for compliance
   */
  async exportAuditData(
    query: AuditQuery,
    format: 'JSON' | 'CSV' | 'PDF' = 'JSON'
  ): Promise<{
    data: any;
    filename: string;
    contentType: string;
  }> {
    return await executeWithMetrics(async () => {
      const auditEntries = await this.queryAuditTrail(query);
      const timestamp = new Date().toISOString().slice(0, 10);
      
      switch (format) {
        case 'JSON':
          return {
            data: JSON.stringify(auditEntries, null, 2),
            filename: `astral-audit-${timestamp}.json`,
            contentType: 'application/json',
          };
          
        case 'CSV':
          const csvData = this.convertToCSV(auditEntries);
          return {
            data: csvData,
            filename: `astral-audit-${timestamp}.csv`,
            contentType: 'text/csv',
          };
          
        case 'PDF':
          // In production, would generate actual PDF
          const pdfData = `Audit Report - ${timestamp}\n\nTotal Decisions: ${auditEntries.length}`;
          return {
            data: pdfData,
            filename: `astral-audit-${timestamp}.pdf`,
            contentType: 'application/pdf',
          };
          
        default:
          throw new Error(`Unsupported export format: ${format}`);
      }
      
    }, 'audit-export-data');
  }
  
  // Private helper methods
  
  private sanitizeContent(content: string): string {
    // Remove or mask sensitive information while preserving analysis value
    let sanitized = content;
    
    // Mask potential PII
    sanitized = sanitized.replace(/\b\d{3}-\d{3}-\d{4}\b/g, '[PHONE-REDACTED]');
    sanitized = sanitized.replace(/\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\.[A-Z|a-z]{2,}\b/g, '[EMAIL-REDACTED]');
    sanitized = sanitized.replace(/\b\d{4}[\s-]?\d{4}[\s-]?\d{4}[\s-]?\d{4}\b/g, '[CARD-REDACTED]');
    
    // Limit length for storage efficiency
    if (sanitized.length > this.AUDIT_CONFIG.MAX_CONTENT_LENGTH) {
      sanitized = sanitized.substring(0, this.AUDIT_CONFIG.MAX_CONTENT_LENGTH) + '[TRUNCATED]';
    }
    
    return sanitized;
  }
  
  private hashSensitiveData(inputData: AuditEntry['inputData']): string {
    // Create hash of sensitive data for matching without storing original
    const crypto = require('crypto');
    const dataToHash = JSON.stringify({
      content: inputData.content,
      userId: inputData.userId,
      sessionId: inputData.sessionId,
    });
    
    return crypto.createHash('sha256').update(dataToHash).digest('hex');
  }
  
  private determineRegulatoryFlags(
    decisionType: AuditEntry['decisionType'],
    aiDecision: AuditEntry['aiDecision']
  ): string[] {
    const flags: string[] = [];
    
    // Crisis-related decisions require special handling
    if (decisionType === 'CRISIS_DETECTION' || aiDecision.actions.includes('EMERGENCY_SERVICES_IMMEDIATELY')) {
      flags.push('MENTAL_HEALTH_INTERVENTION');
    }
    
    // High-risk decisions
    if (aiDecision.riskScore >= 0.9) {
      flags.push('HIGH_RISK_DECISION');
    }
    
    // Content blocking decisions
    if (aiDecision.actions.includes('BLOCK_MESSAGE')) {
      flags.push('CONTENT_RESTRICTION');
    }
    
    // Quality assessment failures
    if (decisionType === 'QUALITY_ASSESSMENT' && aiDecision.riskScore >= 0.7) {
      flags.push('VOLUNTEER_PERFORMANCE');
    }
    
    return flags;
  }
  
  private async alertComplianceTeam(auditEntry: AuditEntry): Promise<void> {
    // In production, would send alerts to compliance team
    console.log(`üö® COMPLIANCE ALERT: Critical AI decision logged - ${auditEntry.id}`);
  }
  
  private dbRecordToAuditEntry(record: any): AuditEntry {
    return {
      id: record.id,
      timestamp: record.timestamp,
      decisionType: record.decisionType,
      inputData: {
        content: record.content,
        context: JSON.parse(record.inputContext || '{}'),
        userId: record.userId,
        sessionId: record.sessionId,
      },
      aiDecision: {
        riskScore: record.riskScore,
        confidence: record.confidence,
        reasoning: JSON.parse(record.reasoning || '[]'),
        categories: JSON.parse(record.categories || '[]'),
        actions: JSON.parse(record.actions || '[]'),
      },
      humanOverride: record.humanOverrideBy ? {
        overriddenBy: record.humanOverrideBy,
        overrideReason: record.humanOverrideReason,
        newDecision: record.humanOverrideDecision,
        timestamp: record.humanOverrideTimestamp,
      } : undefined,
      outcome: record.outcomeRecorded ? {
        actualRisk: record.actualRisk,
        falsePositive: record.falsePositive,
        falseNegative: record.falseNegative,
        userFeedback: record.userFeedback,
        effectiveness: record.effectiveness,
      } : undefined,
      compliance: {
        dataRetentionDays: record.retentionDays,
        anonymized: record.anonymized,
        regulatoryFlags: JSON.parse(record.regulatoryFlags || '[]'),
      },
    };
  }
  
  private async calculateTrends(auditEntries: AuditEntry[]): Promise<any> {
    // Group by day for trend analysis
    const dailyStats = new Map<string, {
      count: number;
      avgRisk: number;
      falsePositives: number;
      humanOverrides: number;
    }>();
    
    auditEntries.forEach(entry => {
      const date = entry.timestamp.toISOString().slice(0, 10);
      const existing = dailyStats.get(date) || {
        count: 0,
        avgRisk: 0,
        falsePositives: 0,
        humanOverrides: 0,
      };
      
      existing.count++;
      existing.avgRisk = (existing.avgRisk * (existing.count - 1) + entry.aiDecision.riskScore) / existing.count;
      if (entry.outcome?.falsePositive) existing.falsePositives++;
      if (entry.humanOverride) existing.humanOverrides++;
      
      dailyStats.set(date, existing);
    });
    
    return Object.fromEntries(dailyStats);
  }
  
  private convertToCSV(auditEntries: AuditEntry[]): string {
    const headers = [
      'ID',
      'Timestamp',
      'Decision Type',
      'Risk Score',
      'Confidence',
      'Actions',
      'Human Override',
      'False Positive',
      'False Negative',
    ];
    
    const rows = auditEntries.map(entry => [
      entry.id,
      entry.timestamp.toISOString(),
      entry.decisionType,
      entry.aiDecision.riskScore.toString(),
      entry.aiDecision.confidence.toString(),
      entry.aiDecision.actions.join(';'),
      entry.humanOverride ? 'Yes' : 'No',
      entry.outcome?.falsePositive ? 'Yes' : 'No',
      entry.outcome?.falseNegative ? 'Yes' : 'No',
    ]);
    
    return [headers, ...rows].map(row => row.join(',')).join('\n');
  }
  
  private startAuditMaintenance(): void {
    // Clean up expired audit entries daily
    setInterval(async () => {
      try {
        const now = new Date();
        const cutoffDate = new Date(now.getTime() - (30 * 24 * 60 * 60 * 1000)); // 30 days ago
        
        // Anonymize old entries
        await prisma.auditTrail.updateMany({
          where: {
            timestamp: { lt: cutoffDate },
            anonymized: false,
          },
          data: {
            userId: null,
            sessionId: null,
            inputDataHash: null,
            anonymized: true,
          },
        });
        
        console.log('üßπ Daily audit maintenance completed');
      } catch (error) {
        console.error('‚ùå Audit maintenance failed:', error);
      }
    }, 24 * 60 * 60 * 1000); // Daily
    
    // Generate weekly compliance reports
    setInterval(async () => {
      try {
        const weekAgo = new Date(Date.now() - (7 * 24 * 60 * 60 * 1000));
        const analysis = await this.generateAuditAnalysis({
          startDate: weekAgo,
          includeOutcomes: true,
        });
        
        console.log(`üìä Weekly AI Safety Metrics:
          - Decisions: ${analysis.totalDecisions}
          - Accuracy: ${(analysis.accuracyRate * 100).toFixed(1)}%
          - False Positive Rate: ${(analysis.falsePositiveRate * 100).toFixed(2)}%
          - Human Override Rate: ${(analysis.humanOverrideRate * 100).toFixed(2)}%`);
        
      } catch (error) {
        console.error('‚ùå Weekly compliance report failed:', error);
      }
    }, 7 * 24 * 60 * 60 * 1000); // Weekly
  }
}